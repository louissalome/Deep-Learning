{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<h1 style = \"text-align : center; border : 1px black solid; padding : 20px; width:100%;\"> DL. Task 2</h1>\n",
    "\n",
    "<h5 style = \"text-align : right;\">Louis Salom√©</h5>\n",
    "\n",
    "<br>Here are the main parts of this notebook :\n",
    "<ol>\n",
    "<li>Load MNIST dataset</li>\n",
    "<li>Train random forest classifier on train data. Evaluate models on test data. Use accuracy score as main evaluation metric</li>\n",
    "<li>Train MLP on train data. Evaluate MLP on test data. Compare with previous results</li>\n",
    "<li>Add random normal noise to train and test data. Then, repeat step #2 on noisy data</li>\n",
    "<li>Train Simple (Non convolutional) Denoising Autoencoder and reconstruct data from data with noise. Repeat step #2 on reconstructed data.</li>\n",
    "<li>Compare all results</li>\n",
    "</ol>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### import part\n",
    "\n",
    "# Process data\n",
    "import numpy as np\n",
    "\n",
    "# Plot graphics\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Measure time\n",
    "import time\n",
    "from time import time, mktime\n",
    "\n",
    "#Simulate randomness\n",
    "import random as rd\n",
    "\n",
    "# Load Data\n",
    "import keras\n",
    "from keras.datasets.mnist import load_data\n",
    "\n",
    "# Model selection\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Deep Learning\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Use only one of the 4 GPUs\n",
    "# Using the command nvidia-sim we can chose the freest GPU\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' # Here is the NUMBER_OF_GPU\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MINST dataset\n",
    "\n",
    "MNIST database of handwritten digits\n",
    "Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set : 60000 image of size 28 x 28 .\n",
      "Test set  : 10000 image of size 28 x 28 .\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "[m    ,h,w] = np.shape(x_train)\n",
    "[mtest,h,w] = np.shape(x_test)\n",
    "print(\"Train set :\",m,\"image of size\",h,\"x\",w,\".\")\n",
    "print(\"Test set  :\",mtest,\"image of size\",h,\"x\",w,\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use it in our models, we have to reshape these images of 28x28 pixels into vectors of shape 784x1. We also normalize the data as it is a good practice in machine learning to have values between in [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = keras.utils.normalize(x_train,axis=1)\n",
    "x_test = keras.utils.normalize(x_test,axis=1)\n",
    "\n",
    "x_train = np.reshape(x_train, (m, h*w))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (mtest, h*w))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is how an image of the dataset looks like :\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = rd.randint(0,60000-1)\n",
    "print(\"This is how an image of the dataset looks like :\")\n",
    "plt.imshow(x_train[r].reshape((h,w)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random forest classifier\n",
    "\n",
    "We first initialize our forest by setting its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFtrainedOnOrginalData = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion = 'gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we fit the classifier with x_train. If the amound of data is too big, this fitting can be quite long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for fitting :  62.96 secondes.\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "RFtrainedOnOrginalData.fit(x_train, y_train)\n",
    "print(\"Elapsed time for fitting : \", round(time()-start,2),\"secondes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally predict results for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = RFtrainedOnOrginalData.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need an function to evaluate the accuracy of this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found an accuracy of 96.92 %.\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_predict, normalize=True)\n",
    "print(\"We found an accuracy of\",round(100*acc,2),\"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multi-layer Perceptron\n",
    "\n",
    "We first initialize our classifier by setting its parameters.\n",
    "\n",
    "Code inspired from youtube video : https://www.youtube.com/watch?v=wQ8BIBpya2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2952 - acc: 0.8759\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1297 - acc: 0.9406\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0999 - acc: 0.9543\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0819 - acc: 0.9628\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0700 - acc: 0.9680\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0612 - acc: 0.9719\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0545 - acc: 0.9753\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0482 - acc: 0.9778\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0429 - acc: 0.9803\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0383 - acc: 0.9827\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0356 - acc: 0.9839\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0329 - acc: 0.9849\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0307 - acc: 0.9860\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0289 - acc: 0.9867\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0268 - acc: 0.9878\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0259 - acc: 0.9881\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0238 - acc: 0.9890\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0226 - acc: 0.9896\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0219 - acc: 0.9897\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0202 - acc: 0.9905\n",
      "Elapsed time for fitting :  44.24 secondes.\n"
     ]
    }
   ],
   "source": [
    "# Architecture\n",
    "MLPtrainedOnOriginalData = Sequential()\n",
    "#model.add(Flatten())\n",
    "MLPtrainedOnOriginalData.add(Dense(128, activation=tf.nn.relu, input_dim=h*w))\n",
    "MLPtrainedOnOriginalData.add(Dense(64, activation=tf.nn.relu))\n",
    "MLPtrainedOnOriginalData.add(Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "# Compilation\n",
    "MLPtrainedOnOriginalData.compile(\n",
    "              optimizer='adam',\n",
    "              loss='categorical_hinge',\n",
    "              metrics=['accuracy'])\n",
    "# model will be our mlp for the whole lab\n",
    "\n",
    "# Training\n",
    "start = time()\n",
    "MLPtrainedOnOriginalData.fit(x_train, keras.utils.np_utils.to_categorical(y_train), epochs=20, batch_size=128)\n",
    "print(\"Elapsed time for fitting : \", round(time()-start,2),\"secondes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found an accuracy of 97.29 %.\n"
     ]
    }
   ],
   "source": [
    "# Predicting\n",
    "y_predict_onehot = MLPtrainedOnOriginalData.predict([x_test])\n",
    "y_predict = np.zeros(mtest)\n",
    "for i in range(mtest):\n",
    "    y_predict[i] = np.argmax(y_predict_onehot[i])\n",
    "    \n",
    "# Calculating accuracy\n",
    "acc = accuracy_score(y_predict,y_test)\n",
    "print(\"We found an accuracy of\",round(100*acc,2),\"%.\")\n",
    "\n",
    "# Quicker & specific to keras :\n",
    "# val_loss, val_acc = model.evaluate(x_test,y_test)\n",
    "# print(\"We found an accuracy of\",round(100*val_acc,2),\"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Noisy Data\n",
    "\n",
    "In this part we are going to add some noise to the data and observe its consequence on the classification.\n",
    "\n",
    "##### 4.1 Add noise on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanNoise = 0\n",
    "stdNoise = 0.2 #This means that a typical noise will be +0.3 or -0.3 on every pixel\n",
    "   \n",
    "x_train_noisy = x_train + np.random.normal(loc=meanNoise, scale=stdNoise, size=x_train.shape) \n",
    "x_test_noisy  = x_test  + np.random.normal(loc=meanNoise, scale=stdNoise, size=x_test.shape) \n",
    "\n",
    "# The data must stay in [0,1]\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is how an image of the dataset looks like : (image number 16267 )\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's visualize our noisy data\n",
    "r = rd.randint(0,60000-1)\n",
    "print(\"This is how an image of the dataset looks like : (image number\",r,\")\")\n",
    "f, axarr = plt.subplots(1,2, figsize=(12,5))\n",
    "axarr[0].imshow(x_train[r].reshape((h,w)), cmap='gray')\n",
    "axarr[0].set_title(\"Original Image\")\n",
    "axarr[1].imshow(x_train_noisy[r].reshape((h,w)),cmap='gray')\n",
    "axarr[1].set_title(\"Noisy Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same classification as before on this noisy dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Random forest classifier on noisy data\n",
    "\n",
    "Same as section 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for fitting :  13.7 secondes.\n",
      "We found an accuracy of 82.94 %.\n"
     ]
    }
   ],
   "source": [
    "RFtrainedOnNoisyData = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    criterion = 'gini')\n",
    "start=time()\n",
    "RFtrainedOnNoisyData.fit(x_train_noisy, y_train)\n",
    "print(\"Elapsed time for fitting : \", round(time()-start,2),\"secondes.\")\n",
    "y_predict = RFtrainedOnNoisyData.predict(x_test)\n",
    "acc = accuracy_score(y_predict,y_test)\n",
    "print(\"We found an accuracy of\",round(100*acc,2),\"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Multi-layer perceptron on noisy data\n",
    "\n",
    "Same as section 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.5530 - acc: 0.7370\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.2872 - acc: 0.8674\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.2437 - acc: 0.8849\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2191 - acc: 0.8966\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1984 - acc: 0.9056\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1822 - acc: 0.9139\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1698 - acc: 0.9193\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1562 - acc: 0.9262\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1462 - acc: 0.9302\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1381 - acc: 0.9344\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1291 - acc: 0.9385\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1216 - acc: 0.9423\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1153 - acc: 0.9448\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1102 - acc: 0.9474\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1037 - acc: 0.9502\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1006 - acc: 0.9514\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0966 - acc: 0.9535\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0933 - acc: 0.9546\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0894 - acc: 0.9563\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0885 - acc: 0.9568\n",
      "Elapsed time for fitting :  45.98 secondes.\n"
     ]
    }
   ],
   "source": [
    "# Training on noisy data\n",
    "# Architecture\n",
    "MLPtrainedOnNoisyData = Sequential()\n",
    "#model.add(Flatten())\n",
    "MLPtrainedOnNoisyData.add(Dense(128, activation=tf.nn.relu, input_dim=h*w))\n",
    "MLPtrainedOnNoisyData.add(Dense(64, activation=tf.nn.relu))\n",
    "MLPtrainedOnNoisyData.add(Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "# Compilation\n",
    "MLPtrainedOnNoisyData.compile(\n",
    "              optimizer='adam',\n",
    "              loss='categorical_hinge',\n",
    "              metrics=['accuracy'])\n",
    "# model will be our mlp for the whole lab\n",
    "\n",
    "# Training\n",
    "start = time()\n",
    "MLPtrainedOnNoisyData.fit(x_train_noisy, keras.utils.np_utils.to_categorical(y_train), epochs=20, batch_size=128)\n",
    "print(\"Elapsed time for fitting : \", round(time()-start,2),\"secondes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found an accuracy of 94.55 %.\n"
     ]
    }
   ],
   "source": [
    "# Predicting\n",
    "y_predict_onehot = MLPtrainedOnNoisyData.predict([x_test])\n",
    "y_predict = np.zeros(mtest)\n",
    "for i in range(mtest):\n",
    "    y_predict[i] = np.argmax(y_predict_onehot[i])\n",
    "    \n",
    "# Calculating accuracy\n",
    "acc = accuracy_score(y_predict,y_test)\n",
    "print(\"We found an accuracy of\",round(100*acc,2),\"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Denoising autoencoder\n",
    "\n",
    "In this part we are going to reduce the noise we added before so that we find a smoother version than original data without too much noise.\n",
    "\n",
    "##### 5.1 Building an autoencoder\n",
    "\n",
    "Code from : https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "We first build the architecture of the autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This algorithm was designed for a four-dimension dataset.\n",
    "x_train = np.reshape(x_train, (m    , 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test  = np.reshape(x_test , (mtest, 28, 28, 1))  # adapt this if using `channels_first` image data format \n",
    "\n",
    "x_train_noisy = np.reshape(x_train_noisy, (m    , 28, 28, 1))\n",
    "x_test_noisy  = np.reshape(x_test_noisy , (mtest, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (7, 7, 32)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1542 - val_loss: 0.1242\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1206 - val_loss: 0.1205\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1179 - val_loss: 0.1181\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1166 - val_loss: 0.1173\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1159 - val_loss: 0.1161\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1153 - val_loss: 0.1156\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1150 - val_loss: 0.1155\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1146 - val_loss: 0.1150\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1144 - val_loss: 0.1149\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1142 - val_loss: 0.1149\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1140 - val_loss: 0.1144\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1138 - val_loss: 0.1144\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1137 - val_loss: 0.1142\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1136 - val_loss: 0.1141\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1134 - val_loss: 0.1144\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1133 - val_loss: 0.1142\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1132 - val_loss: 0.1139\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1131 - val_loss: 0.1138\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1130 - val_loss: 0.1137\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1130 - val_loss: 0.1137\n",
      "Elapsed time for fitting : 96.09 secondes.\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=20,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test)\n",
    "                #callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)]\n",
    "               )\n",
    "print(\"Elapsed time for fitting :\", round(time()-start,2),\"secondes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can produce our new denoised data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_denoised = autoencoder.predict(x_train_noisy)\n",
    "x_test_denoised = autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (m    , h*w)) \n",
    "x_test  = np.reshape(x_test , (mtest, h*w))\n",
    "x_train_noisy = np.reshape(x_train_noisy, (m    , h*w)) \n",
    "x_test_noisy  = np.reshape(x_test_noisy , (mtest, h*w))\n",
    "x_train_denoised = np.reshape(x_train_denoised, (m    , h*w)) \n",
    "x_test_denoised  = np.reshape(x_test_denoised , (mtest, h*w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is how an image of the dataset looks like : (image number 34018 )\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to look at a new image !\n",
    "r = rd.randint(0,60000-1)\n",
    "print(\"This is how an image of the dataset looks like : (image number\",r,\")\")\n",
    "f, axarr = plt.subplots(1,3, figsize=(18,5))\n",
    "axarr[0].imshow(x_train[r].reshape((h,w)), cmap='gray')\n",
    "axarr[0].set_title(\"Original Image\")\n",
    "axarr[1].imshow(x_train_noisy[r].reshape((h,w)),cmap='gray')\n",
    "axarr[1].set_title(\"Noisy Image\")\n",
    "axarr[2].imshow(x_train_denoised[r].reshape((h,w)),cmap='gray')\n",
    "axarr[2].set_title(\"Denoised Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2 Random forest classifier on denoised data\n",
    "\n",
    "Same as section 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for fitting :  214.27 secondes.\n",
      "We found an accuracy of 90.58 %.\n"
     ]
    }
   ],
   "source": [
    "RFtrainedOnDenoisedData = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion = 'gini')\n",
    "start=time()\n",
    "RFtrainedOnDenoisedData.fit(x_train_denoised, y_train)\n",
    "print(\"Elapsed time for fitting : \", round(time()-start,2),\"secondes.\")\n",
    "y_predict = RFtrainedOnDenoisedData.predict(x_test)\n",
    "acc = accuracy_score(y_predict,y_test)\n",
    "print(\"We found an accuracy of\",round(100*acc,2),\"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3 Multi-layer perceptron on denoised data\n",
    "\n",
    "Same as section 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.3355 - acc: 0.8568\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1766 - acc: 0.9175\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1482 - acc: 0.9297\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1306 - acc: 0.9381\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1186 - acc: 0.9439\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1089 - acc: 0.9481\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1003 - acc: 0.9526\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0927 - acc: 0.9563\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0878 - acc: 0.9587\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0830 - acc: 0.9612\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0787 - acc: 0.9631\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0746 - acc: 0.9652\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0719 - acc: 0.9660\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0673 - acc: 0.9680\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0653 - acc: 0.9691\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0624 - acc: 0.9709\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0603 - acc: 0.9716\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0583 - acc: 0.9724\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0564 - acc: 0.9732\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0556 - acc: 0.9737\n",
      "Elapsed time for fitting :  45.92 secondes.\n"
     ]
    }
   ],
   "source": [
    "# Training on denoised data\n",
    "# Architecture\n",
    "MLPtrainedOnDenoisedData = Sequential()\n",
    "#model.add(Flatten())\n",
    "MLPtrainedOnDenoisedData.add(Dense(128, activation=tf.nn.relu, input_dim=h*w))\n",
    "MLPtrainedOnDenoisedData.add(Dense(64, activation=tf.nn.relu))\n",
    "MLPtrainedOnDenoisedData.add(Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "# Compilation\n",
    "MLPtrainedOnDenoisedData.compile(\n",
    "              optimizer='adam',\n",
    "              loss='categorical_hinge',\n",
    "              metrics=['accuracy'])\n",
    "# model will be our mlp for the whole lab\n",
    "\n",
    "# Training\n",
    "start = time()\n",
    "MLPtrainedOnDenoisedData.fit(x_train_denoised, keras.utils.np_utils.to_categorical(y_train), epochs=20, batch_size=128)\n",
    "print(\"Elapsed time for fitting : \", round(time()-start,2),\"secondes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found an accuracy of 96.88 %.\n"
     ]
    }
   ],
   "source": [
    "# Predicting\n",
    "y_predict_onehot = MLPtrainedOnDenoisedData.predict([x_test])\n",
    "y_predict = np.zeros(mtest)\n",
    "for i in range(mtest):\n",
    "    y_predict[i] = np.argmax(y_predict_onehot[i])\n",
    "    \n",
    "# Calculating accuracy\n",
    "acc = accuracy_score(y_predict,y_test)\n",
    "print(\"We found an accuracy of\",round(100*acc,2),\"%.\")\n",
    "\n",
    "# Quicker & specific to keras :\n",
    "# val_loss, val_acc = model.evaluate(x_test,y_test)\n",
    "# print(\"We found an accuracy of\",round(100*val_acc,2),\"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusion\n",
    "\n",
    "To sum up, we trained 2 models of Machine Learning on 3 differents types of data :\n",
    "<ul>\n",
    "    <li>The original data</li>\n",
    "    <li>The noisy data</li>\n",
    "    <li>The denoised data</li>\n",
    "</ul>\n",
    "\n",
    "Now we will see how good these differents models are to make predictions on the 3 differents types of test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "accRForginalXoriginal = round(100*accuracy_score(RFtrainedOnOrginalData.predict(x_test),y_test),3)\n",
    "accRForginalXnoisy    = round(100*accuracy_score(RFtrainedOnOrginalData.predict(x_test_noisy),y_test),3)\n",
    "accRForginalXdenoised = round(100*accuracy_score(RFtrainedOnOrginalData.predict(x_test_denoised),y_test),3)\n",
    "\n",
    "accRFnoisyXoriginal  = round(100*accuracy_score(RFtrainedOnNoisyData.predict(x_test),y_test),3)\n",
    "accRFnoisyXnoisy     = round(100*accuracy_score(RFtrainedOnNoisyData.predict(x_test_noisy),y_test),3)\n",
    "accRFnoisylXdenoised = round(100*accuracy_score(RFtrainedOnNoisyData.predict(x_test_denoised),y_test),3)\n",
    "\n",
    "accRFdenoisedXoriginal  = round(100*accuracy_score(RFtrainedOnDenoisedData.predict(x_test),y_test),3)\n",
    "accRFdenoisedXnoisy     = round(100*accuracy_score(RFtrainedOnDenoisedData.predict(x_test_noisy),y_test),3)\n",
    "accRFdenoisedlXdenoised = round(100*accuracy_score(RFtrainedOnDenoisedData.predict(x_test_denoised),y_test),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 52us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.056127648037672041, 0.97289999999999999]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLPtrainedOnOriginalData.evaluate(x_test, keras.utils.np_utils.to_categorical(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 54us/step\n",
      "10000/10000 [==============================] - 1s 55us/step\n",
      "10000/10000 [==============================] - 1s 51us/step\n",
      "10000/10000 [==============================] - 1s 56us/step\n",
      "10000/10000 [==============================] - 1s 56us/step\n",
      "10000/10000 [==============================] - 1s 56us/step\n",
      "10000/10000 [==============================] - 1s 61us/step\n",
      "10000/10000 [==============================] - 1s 57us/step\n",
      "10000/10000 [==============================] - 1s 50us/step\n"
     ]
    }
   ],
   "source": [
    "accMLPorginalXoriginal = round(100*MLPtrainedOnOriginalData.evaluate(x_test, keras.utils.np_utils.to_categorical(y_test))[1],2)\n",
    "accMLPorginalXnoisy    = round(100*MLPtrainedOnOriginalData.evaluate(x_test_noisy,keras.utils.np_utils.to_categorical(y_test))[1],2)\n",
    "accMLPorginalXdenoised = round(100*MLPtrainedOnOriginalData.evaluate(x_test_denoised,keras.utils.np_utils.to_categorical(y_test))[1],2)\n",
    "\n",
    "accMLPnoisyXoriginal  = round(100*MLPtrainedOnNoisyData.evaluate(x_test, keras.utils.np_utils.to_categorical(y_test))[1],2)\n",
    "accMLPnoisyXnoisy     = round(100*MLPtrainedOnNoisyData.evaluate(x_test_noisy,keras.utils.np_utils.to_categorical(y_test))[1],2)\n",
    "accMLPnoisylXdenoised = round(100*MLPtrainedOnNoisyData.evaluate(x_test_denoised,keras.utils.np_utils.to_categorical(y_test))[1],2)\n",
    "\n",
    "accMLPdenoisedXoriginal  = round(100*MLPtrainedOnDenoisedData.evaluate(x_test,keras.utils.np_utils.to_categorical(y_test))[1],2)\n",
    "accMLPdenoisedXnoisy     = round(100*MLPtrainedOnDenoisedData.evaluate(x_test_noisy,keras.utils.np_utils.to_categorical(y_test))[1],2)\n",
    "accMLPdenoisedlXdenoised = round(100*MLPtrainedOnDenoisedData.evaluate(x_test_denoised,keras.utils.np_utils.to_categorical(y_test))[1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             | Orginal Data    | Noisy Data    | Denoised Data    |\n",
      "RF  trained on original Data | 96.92 %         | 50.09 %       | 88.82 %          |\n",
      "RF  trained on noisy Data    | 82.94 %         | 60.94 %       | 79.17 %          |\n",
      "RF  trained on denoised Data | 90.58 %         | 51.39 %       | 94.01 %          |\n",
      "                             |----------------------------------------------------|\n",
      "MLP trained on original Data | 97.29 %         | 56.06 %       | 94.61 %          |\n",
      "MLP trained on noisy Data    | 94.55 %         | 90.51 %       | 91.64 %          |\n",
      "MLP trained on denoised Data | 96.88 %         | 51.19 %       | 95.21 %          |\n"
     ]
    }
   ],
   "source": [
    "print(\"                             |\",\"Orginal Data    |\",\"Noisy Data    |\",\"Denoised Data    |\")\n",
    "print(\"RF  trained on original Data |\",accRForginalXoriginal,\"%         |\",accRForginalXnoisy,\"%       |\",accRForginalXdenoised,\"%          |\")\n",
    "print(\"RF  trained on noisy Data    |\",accRFnoisyXoriginal,\"%         |\",accRFnoisyXnoisy,\"%       |\",accRFnoisylXdenoised,\"%          |\")\n",
    "print(\"RF  trained on denoised Data |\",accRFdenoisedXoriginal,\"%         |\",accRFdenoisedXnoisy,\"%       |\",accRFdenoisedlXdenoised,\"%          |\")\n",
    "print(\"                             |----------------------------------------------------|\")\n",
    "print(\"MLP trained on original Data |\",accMLPorginalXoriginal,\"%         |\",accMLPorginalXnoisy,\"%       |\",accMLPorginalXdenoised,\"%          |\")\n",
    "print(\"MLP trained on noisy Data    |\",accMLPnoisyXoriginal,\"%         |\",accMLPnoisyXnoisy,\"%       |\",accMLPnoisylXdenoised,\"%          |\")\n",
    "print(\"MLP trained on denoised Data |\",accMLPdenoisedXoriginal,\"%         |\",accMLPdenoisedXnoisy,\"%       |\",accMLPdenoisedlXdenoised,\"%          |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's draw conclusions. We should not compare directly RF and MLP because each classifier can be improved by setting some parameters (e.g. Use a bigger forest, set a max_depth or use a bigger NN, increase the number of epochs...).\n",
    "\n",
    "First, about RF :\n",
    "<ul>\n",
    "    <li>The best score is reached with the RF trained on original data and used on original data, the mst classic one.</li>\n",
    "    <li>We can say that the RF are always bad when the data is too noisy. Even the one trained on noisy data is bad.</li>\n",
    "</ul>\n",
    "\n",
    "Then, about MLP :\n",
    "<ul>\n",
    "    <li>The first thing we notice is that the best of them all to predict y_test is the MLP trained on orginal data.\n",
    "However, this one is very bad at classifying noisy data. It has never seen a noisy image so it's lost when it has to deal with noisy data.</li>\n",
    "    <li>The MLP trained on noisy data is really interesting because it has great score on every types of data. It is very good in average. So this might be the one we should use if we really don't know what kind of data will come next.</li>\n",
    "    <li>The MLP trained on denoised data has two very high scores on original and denoised data. Even if it can't understand noisy image, it is maybe the one which understands the most important features of an image of number. We can suppose that some artefacts of the original data were detected as important features by the other algorithms, but it was a mistake to give importance to it. The noise made these particularities disappear by smoothing the data, uniformizing it.</li>\n",
    "</ul>\n",
    "\n",
    "Among all these facts, I think that the most interesting one is that the MLP trained on denoised data had a better score on original data than on denoised data, and this one is really high. By learning on smooth and fuzzy data, it must have a very small overfitting on the original dataset. The final score on original data is pretty close to the best one. We can suppose that the mistakes that this algorithms makes are more \"human\" than the mistakes of the others algorithms. It just learned the global idea of the shape of each number and not just focused on some specific artefacts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
